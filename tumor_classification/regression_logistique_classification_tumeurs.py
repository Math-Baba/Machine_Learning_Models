# -*- coding: utf-8 -*-
"""regression_logistique_classification_tumeurs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Math-Baba/Machine_Learning_Models/blob/main/tumor_classification/regression_logistique_classification_tumeurs.ipynb

**Objectif :** Mettre en œuvre un modèle de classification binaire. Nous allons utiliser la régression logistique pour prédire si une tumeur est bénigne ou maligne. Nous allons ici introduire l'importance de la **mise à l'échelle (scaling)** des données.
"""

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1. Charger
cancer = load_breast_cancer()
X = cancer.data
y = cancer.target

print(f"Nombre de features : {X.shape[1]}")
print(f"Classes : {cancer.target_names}") # 0 = malignant, 1 = bénigne

# 3. Constater les échelles
print(f"Moyenne feature 0 : {X[:, 0].mean():.2f}")
print(f"Moyenne feature 3 : {X[:, 3].mean():.2f}")

# 4. Diviser
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""### **Importance de la mise à l'échelle (Standardisation)**

**Pourquoi ?** De nombreux algorithmes (Régression Logistique, SVM, Réseaux de Neurones) sont sensibles à l'échelle des données. Si une feature varie de 0 à 1 et une autre de 0 à 1 000 000, le modèle risque de donner une importance démesurée à la seconde, simplement à cause de son échelle, et non de son pouvoir prédictif.

La **Standardisation** (utilisant `StandardScaler`) est la technique la plus courante. Elle transforme les données pour qu'elles aient une moyenne de 0 et un écart-type de 1.

**Règle d'or (TRÈS IMPORTANT) :**
1.  On "adapte" (calcule la moyenne et l'écart-type) le scaler **uniquement** sur les données d'entraînement (`.fit(X_train)`).
2.  On applique ensuite cette transformation (avec la moyenne et l'écart-type du *train*) aux données d'entraînement (`.transform(X_train)`) ET de test (`.transform(X_test)`).

Cela évite toute "fuite d'information" du set de test vers le modèle.
"""

# 1. Créer le scaler
scaler = StandardScaler()

# 3. Transformer
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

scaler.fit(X_train_scaled, y_train)

# 4. Vérification
print(scaler.mean_[0], scaler.scale_[0])
print(scaler.mean_[3], scaler.scale_[3])

# 1. Créer l'instance
model = LogisticRegression(solver='liblinear')


# 2. Entraîner
model.fit(X_train_scaled, y_train)


# 3. Prédire
y_pred = model.predict(X_test_scaled)


# 4. Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)


# 5. Matrice de confusion
conf_matrix = confusion_matrix(y_test, y_pred)
print("Matrice de confusion:\n", conf_matrix)


# 6. Rapport de classification
class_report = classification_report(y_test, y_pred)
print("Rapport de classification:\n", class_report)